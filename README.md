---
title: Multi-Agent-Model
emoji: ğŸ§ 
colorFrom: purple
colorTo: indigo
sdk: docker
app_file: Dockerfile
pinned: false
license: mit
---
Multi-Agent Research Assistant
Overview:

This project is a modular multi-agent system designed for NebulaByte Technologies to automate AI research assistance tasks such as PDF summarization, web search, and academic paper retrieval.
It integrates FastAPI (backend) and Streamlit (frontend) to create an interactive interface for users to upload PDFs, query research topics, and visualize AI-driven insights.

Key Features:

Controller Agent (Decision Maker):
Dynamically routes user queries to appropriate agents (PDF RAG, Web Search, or ArXiv) using rule-based logic.
Logs all decisions, rationale, and trace files.

PDF RAG Agent:
Extracts, chunks, embeds, and retrieves relevant passages from research PDFs using FAISS and SentenceTransformers.
Provides concise contextual answers or summaries.

Web Search Agent:
Performs live searches using SerpAPI or Google Gemini to fetch the latest AI developments, papers, and news.

ArXiv Agent:
Fetches the latest academic papers from ArXiv.org and summarizes them for easy review.

Frontend:
Built using Streamlit for interactive user experience â€” allowing PDF uploads, query input, and displaying logs or summaries.

Tech Stack:
Layer	Technology
Frontend	Streamlit
Backend	FastAPI
Vector Search	FAISS
Embeddings	SentenceTransformers
LLM API	Gemini / Groq (configurable)
Web Search	SerpAPI
Research Papers	ArXiv API
Language	Python 3.10+

Project Structure:
Solar_assignment/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                 # FastAPI backend
â”‚   â”œâ”€â”€ controller_agent.py     # Core controller logic
â”‚   â”œâ”€â”€ pdf_rag_agent.py        # PDF retrieval + summarization
â”‚   â”œâ”€â”€ web_search_agent.py     # Web Search via SerpAPI
â”‚   â”œâ”€â”€ arxiv_agent.py          # ArXiv integration
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ config.py           # API keys & paths
â”‚   â”‚   â”œâ”€â”€ logger.py           # Logging system
â”‚   â”‚   â””â”€â”€ llm_model.py        # Gemini or Groq LLM wrapper
â”‚   â””â”€â”€ logs/                   # Auto-generated logs/traces
â”‚
â”œâ”€â”€ app.py                      # Streamlit frontend
â”œâ”€â”€ sample_pdfs/                # Curated NebulaByte PDFs for RAG demo
â”œâ”€â”€ requirements.txt            # Dependencies
â””â”€â”€ README.md                   # Project documentation

Installation & Setup
1ï¸ Clone the repository
git clone https://github.com/<your-username>/<your-repo-name>.git
cd <your-repo-name>

2ï¸ Create and activate a virtual environment
python -m venv venv
venv\Scripts\activate   # for Windows
# OR
source venv/bin/activate  # for Mac/Linux

3ï¸ Install dependencies
pip install -r requirements.txt

4ï¸ Create a .env file

Include the following (replace with your actual keys):

GROQ_API_KEY=your_groq_api_key
SERPAPI_KEY=your_serpapi_key
BACKEND_URL=http://localhost:8000

Running the Application:
Start the backend (FastAPI):
python -m uvicorn backend.main:app --reload --port 8000

Start the frontend (Streamlit):
streamlit run app.py


Now open your browser at:

http://localhost:8501

Testing the System:

You can try queries like:

â€œSummarize this uploaded document.â€

â€œShow me the latest AI research papers from ArXiv.â€

â€œRecent projects by NebulaByte Technologies.â€

â€œWhat are developments in quantum AI in 2025?â€

Each response will generate a trace file in /logs detailing:

The decision logic

Agents used

Retrieved documents

Final synthesized answer

Deployment:

You can deploy this project using:

Render (recommended for FastAPI + Streamlit)

Hugging Face Spaces (Gradio/Streamlit mode)

Railway.app or Google Cloud Run

Each deployment should expose:

FastAPI backend (/ask, /upload_pdf, /logs, /check_env)

Streamlit frontend (app.py)

Deliverables:

 Modular multi-agent architecture
 Deployed demo link
 5 curated NebulaByte PDFs in sample_pdfs/
 Logs + trace files demonstrating routing logic
 Detailed REPORT.pdf explaining architecture
